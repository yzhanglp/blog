---
layout: post
title: Research Tricks
subtitle: Some research tricks
cover-img: /assets/img/saber_2.jpg
thumbnail-img: /assets/img/saber_2.png
share-img: /assets/img/saber_2.jpg
tags: [Notes]
author: Yuhao ZHANG
---
# Small Tricks

## Table of Contents
- [Small Tricks](#small-tricks)
  - [Table of Contents](#table-of-contents)
  - [Switch CUDA Version](#switch-cuda-version)
    - [Basic Usage](#basic-usage)
    - [Auto-load configuration](#auto-load-configuration)
  - [GPU Usage in slurm](#gpu-usage-in-slurm)
    - [Allocate GPU](#allocate-gpu)
    - [Check the free GPU](#check-the-free-gpu)
    - [Track the job](#track-the-job)



## Switch CUDA Version
Use enviroment-modules to <mark>switch CUDA version</mark> in different enviroment
### Basic Usage
1. Install enviroment-modules.    
   ```bash
   conda install -c conda-forge environment-modules
   conda install -c conda-forge environment-modules
   ```
2. Create modules file, e.g <mark>CONDA_PREFIX/modulefiles/cuda/11.7</mark>    
   ```bash
   #Create module file in the current enviroment
   mkdir -p $CONDA_PREFIX/modulefiles/cuda
   ```
3. Create and edit the module file <mark>11.8</mark>, an example of module file:

   ```bash
   #%Module1.0
   proc ModulesHelp { } {
       global version
       puts stderr "Sets up environment for CUDA $version"
   }

   module-whatis "sets up environment for CUDA 11.8"

   set version 11.8
   #Use your own CUDA path
   set root /usr/local/cuda-11.8

   setenv CUDA_HOME   $root
   prepend-path PATH    $root/bin
   prepend-path LD_LIBRARY_PATH $root/lib64
   prepend-path MANPATH $root/doc/man

   conflict cuda
   ```
After all this settings, you can load and unload your own CUDA version with following instrctions:
   ```bash
   module load cuda/11.7
   module unload cuda/11.7
   ```
### Auto-load configuration
1. Activation script edition.   
    ```bash
    cat > $CONDA_PREFIX/etc/conda/activate.d/load_cuda.sh << 'EOF'
    #!/bin/bash

    export MODULEPATH=$CONDA_PREFIX/modulefiles:$MODULEPATH

    module load cuda/11.8

    echo "Loaded CUDA 11.8 for this environment"
    EOF
    ```
2. Deactivation script edition.   
   ```bash
   cat > $CONDA_PREFIX/etc/conda/deactivate.d/unload_cuda.sh << 'EOF'
   #!/bin/bash

   module unload cuda

   echo "Unloaded CUDA modules for this environment"
   EOF

   ```
3. Make scripts executable.    
   ```bash
   chmod +x $CONDA_PREFIX/etc/conda/activate.d/load_cuda.sh
   chmod +x $CONDA_PREFIX/etc/conda/deactivate.d/unload_cuda.sh
   ```
After all this, your enviroment can auto load/unload the CUDA module



## GPU Usage in slurm  
Write this only for quick reference  

### Allocate GPU   
- Use the following command to allocate a GPU
  ```bash
  srun --account viscam --partition=viscam-interactive --gres=gpu:a6000:1 --mem=24G --pty bash
  ```   
- Use the following command to also allocate CPU for long term usage:   
  ```bash
  srun --account viscam --partition=viscam-interactive --time=24:00:00 --cpus-per-task=8 --gres=gpu:a40:1 --mem=32G --pty bash
  ```
- use ```mem``` to allocate memory and use ```gres=gpu:a6000:1``` to choose different gpu.    
- Consider using ``` –exclude=viscam5 ``` if don’t need a40s, especially before deadlines    
### Check the free GPU
- Use the following command to check the free GPU:    
  ```bash
  sgpu -p svl,svl-interactive,viscam,viscam-interactive --verbose
  ```

### Track the job
- Use the following command to track the job submission by specific user:  
  ```bash
  squeue -u $USER   
  ```
- To view the status of all jobs in the viscam and viscam-interactive partitions:    
  ```bash
  squeue -p viscam,viscam-interactive
  ```
- To check GPU stats, use:  
  ```bash
  pestat -p viscam -G  
  ``` 

